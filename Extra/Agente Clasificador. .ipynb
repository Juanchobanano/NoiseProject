{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing helper function\n",
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    \n",
    "def setLabel(file_name):\n",
    "    if(file_name.find(\"ruido\")) >= 0: return 0\n",
    "    else: return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files:  ['ruido_1.wav', 'ruido_10.wav', 'ruido_2.wav', 'ruido_3.wav', 'ruido_4.wav', 'ruido_5.wav', 'ruido_6.wav', 'ruido_7.wav', 'ruido_8.wav', 'ruido_9.wav', 'sonido_1.wav', 'sonido_10.wav', 'sonido_2.wav', 'sonido_3.wav', 'sonido_4.wav', 'sonido_5.wav', 'sonido_6.wav', 'sonido_7.wav', 'sonido_8.wav', 'sonido_9.wav']\n",
      "Labels:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Load Training data.\n",
    "sound_files = list()\n",
    "with os.scandir(\"./Audios/training_set\") as entries:\n",
    "    for entry in entries:\n",
    "        sound_files.append(entry.name)\n",
    "\n",
    "labels = list()\n",
    "for s in sound_files:\n",
    "    labels.append(setLabel(s))\n",
    "    \n",
    "print(\"Audio files: \", sound_files)\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbors():\n",
    "    \n",
    "    # Load data.\n",
    "    def __init__(self, X, y, neighbors = 5):\n",
    "        self.sounds = X\n",
    "        self.labels = y\n",
    "        self.neighbors = neighbors\n",
    "        print(\"Classifier initialize!\")\n",
    "        \n",
    "    def predict(self, sound):\n",
    "        \n",
    "        categories = [0, 0]\n",
    "        signal_to_predict = self.processSound(sound)\n",
    "        similar_vector = list()\n",
    "        \n",
    "        # Compute audio similarity.\n",
    "        for s in self.sounds[0:2]:\n",
    "            training_sound = self.processSound(s)\n",
    "            fs = 10e3\n",
    "            f, Cxy = scipy.signal.coherence(signal_to_predict, training_sound, fs, nperseg=1024)\n",
    "            similar_vector.append(Cxy.mean())\n",
    "            training_sound = None\n",
    "            print(s, Cxy.mean())\n",
    "            \n",
    "        # Select K-nearest neigbors.\n",
    "        temp = similar_vector.copy()\n",
    "        nearest_neighbors = list()\n",
    "        contador = 0\n",
    "        \n",
    "        print(temp)\n",
    "        \n",
    "        while(contador < 3):\n",
    "            element = min(temp)\n",
    "            nearest_neighbors.append(element)\n",
    "            temp.remove(element)\n",
    "            contador += 1\n",
    "        \n",
    "        temp = list()\n",
    "            \n",
    "        for k in nearest_neighbors:\n",
    "            \n",
    "            index = similar_vector.index(k)\n",
    "            if labels[index] == 0: \n",
    "                categories[0] += 1\n",
    "            else: \n",
    "                categories[1] += 1\n",
    "                \n",
    "        for c in range(0, len(categories)):\n",
    "            categories[c] = categories[c] / len(self.sounds)\n",
    "            \n",
    "        temp = list()\n",
    "        nearest_neighbors = list()\n",
    "        contador = 0\n",
    "        signal_to_predict = list()\n",
    "        similar_vector = list()\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    # Process Sound.\n",
    "    def processSound(self, sound):\n",
    "        \n",
    "        # Load audio.\n",
    "        pathFile =  \"./Audios/training_set/\" + str(sound)\n",
    "        (sample_rate, input_signal) = scipy.io.wavfile.read(pathFile, mmap = True)\n",
    "\n",
    "        # Convert to mono.\n",
    "        try:\n",
    "            input_signal = input_signal[:,0]\n",
    "        except: \n",
    "            pass\n",
    "    \n",
    "        # Calculate time array (max 10 seconds).\n",
    "        time_array = np.arange(0, len(input_signal)/sample_rate, 1/sample_rate)   \n",
    "        audio_duration_minutes = time_array[-1] / 60\n",
    "\n",
    "        # Print audio duration.\n",
    "        print(\"Sound ready! Duration in minutes: \", audio_duration_minutes)\n",
    "\n",
    "        # Convert input signal to 4000 hz.\n",
    "        input_signal_4000hz = [input_signal[i] for i in range(0, len(input_signal), sample_rate//4000)]\n",
    "        \n",
    "        # Return process audio.\n",
    "        print(len(input_signal_4000hz))\n",
    "        return input_signal_4000hz\n",
    "        \n",
    "    # Get Euclidean Distance between two points.\n",
    "    def getEuclideanDistance(self, p1, p2):\n",
    "        distance = 0\n",
    "        for i in range(0, len(p1)):\n",
    "            distance += (p1[i] - p2[i])**2\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    # Plot results. \n",
    "    def plotResults(self, res):\n",
    "        plt.bar([\"Ruido\", \"No Ruido\"], res, width = 0.5, hatch = \"/\", color = \"red\", edgecolor = \"black\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.title(\"Sound Classification\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()\n",
    "        \n",
    "        if res[0] > res[1]: print(\"Audio classified as NOISE.\")\n",
    "        elif res[1] > res[0]: print(\"Audio classified as SOUND.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier initialize!\n"
     ]
    }
   ],
   "source": [
    "model = NearestNeighbors(sound_files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sound ready! Duration in minutes:  0.16666628873771733\n",
      "40091\n",
      "Sound ready! Duration in minutes:  0.16833295540438398\n",
      "40492\n",
      "ruido_1.wav 0.013681208\n",
      "Sound ready! Duration in minutes:  0.16666628873771733\n",
      "40091\n",
      "ruido_10.wav 0.01265207\n",
      "[0.013681208, 0.01265207]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-089ab9ca908c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-2f252baa7498>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, sound)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontador\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mnearest_neighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "res = model.predict(sound_files[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plotResults(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing helper function\n",
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFile =  \"./Audios/ruido_traffic2.wav\"\n",
    "# Load audio file.\n",
    "(sample_rate, input_signal) = scipy.io.wavfile.read(pathFile, mmap = True)\n",
    "input_signal = input_signal[:,0]\n",
    "time_array = np.arange(0, len(input_signal)/sample_rate, 1/sample_rate)   \n",
    "audio_duration_minutes = time_array[-1] / 60\n",
    "print(\"Sound ready! Duration in minutes: \", audio_duration_minutes)\n",
    "input_signal_8000hz = [input_signal[i] for i in range(0, len(input_signal), sample_rate//8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title=pathFile, x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(time_array, input_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_out = np.fft.rfft(input_signal)\n",
    "fft_mag = [np.sqrt(i.real**2 + i.imag**2)/len(fft_out) for i in fft_out]\n",
    "num_samples = len(input_signal)\n",
    "rfreqs = [(i*1.0/num_samples)*sample_rate for i in range(num_samples//2+1)]\n",
    "\n",
    "setup_graph(title=pathFile, x_label='FFT Bins', y_label='magnitude', fig_size=(14,7))\n",
    "_ = plt.plot(rfreqs[0:5000], fft_mag[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup_graph(title='Spectrogram of diatonic scale ' + str(sample_rate) + \" sample rate\", x_label='time (in seconds)', y_label='frequency', fig_size=(14,8))\n",
    "#_ = plt.specgram(input_signal, Fs=sample_rate)\n",
    "\n",
    "input_signal_4000hz = [input_signal[i] for i in range(0, len(input_signal), sample_rate//4000)]\n",
    "setup_graph(title='Spectrogram (4000Hz sample rate)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(input_signal_4000hz, Fs=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = scipy.signal.spectrogram(input_signal)\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
